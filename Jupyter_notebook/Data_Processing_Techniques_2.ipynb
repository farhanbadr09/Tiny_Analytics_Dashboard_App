{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d03cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1 Function to identify numeric and categorical variables\n",
    "def identify_numeric_categorical(df):\n",
    "    numeric_features = df.select_dtypes(include=['float', 'int']).columns\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "    return numeric_features, categorical_features\n",
    "\n",
    "# 2 Function to drop duplicate rows\n",
    "def drop_duplicates(df):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "# 3 Function to delete incomplete data based on a threshold\n",
    "def delete_incomplete_data(df, threshold=0.8):\n",
    "    return df.dropna(thresh=len(df.columns) * threshold)\n",
    "\n",
    "# Function to fill missing numerical values with mean\n",
    "def fill_missing_with_mean(df, numeric_features):\n",
    "    for feature in numeric_features:\n",
    "        if feature in df.columns:\n",
    "            mean_value = df[feature].mean()\n",
    "            df[feature].fillna(mean_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Function to fill missing categorical values with mode\n",
    "def fill_missing_with_mode(df, categorical_features):\n",
    "    for feature in categorical_features:\n",
    "        if feature in df.columns:\n",
    "            mode_value = df[feature].mode()\n",
    "            if not mode_value.empty:\n",
    "                mode_value = mode_value.iloc[0]\n",
    "                df[feature].fillna(mode_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 4 Function to remove oversampled instances\n",
    "def remove_oversamples(df, max_occurrences=2, min_to_keep=1):\n",
    "    groups = df.groupby(df.columns.tolist(), as_index=False)\n",
    "    \n",
    "    def sample(group):\n",
    "        n = max(min_to_keep, min(len(group), max_occurrences))\n",
    "        if len(group) >= n:\n",
    "            return group.sample(n)\n",
    "        else:\n",
    "            return pd.DataFrame()  # Return an empty DataFrame\n",
    "        \n",
    "    sampled_groups = [sample(group) for _, group in groups]\n",
    "    sampled_groups = [group for group in sampled_groups if not group.empty]  # Remove empty groups\n",
    "    if sampled_groups:\n",
    "        filtered_df = pd.concat(sampled_groups, ignore_index=True)\n",
    "        return filtered_df\n",
    "    else:\n",
    "        return df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to remove incomplete rows based on relevant columns\n",
    "def remove_incomplete_irrelevant_responses(df, relevant_columns):\n",
    "    existing_columns = [col for col in relevant_columns if col in df.columns]\n",
    "    return df.dropna(subset=existing_columns)\n",
    "\n",
    "def one_hot_encode(df, categorical_features=None):\n",
    "    if categorical_features is None:\n",
    "        categorical_features = df.select_dtypes(include=['object']).columns\n",
    "        \n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "    return df_encoded\n",
    "\n",
    "# Function to detect and handle outliers in numeric features using IQR\n",
    "def handle_outliers(df, numeric_features, lower_factor=1.5, upper_factor=1.5):\n",
    "    for feature in numeric_features:\n",
    "        if feature in df.columns:\n",
    "            Q1 = df[feature].quantile(0.25)\n",
    "            Q3 = df[feature].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - (lower_factor * IQR)\n",
    "            upper_bound = Q3 + (upper_factor * IQR)\n",
    "            \n",
    "            df[feature] = np.where((df[feature] < lower_bound) | (df[feature] > upper_bound),\n",
    "                                   df[feature].mean(), df[feature])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to normalize numeric features using StandardScaler\n",
    "def normalize_numeric_features(df, numeric_features):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df[numeric_features])\n",
    "    df[numeric_features] = scaled_data\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, numeric_features, categorical_features, threshold=0.8, relevant_columns=['Response1', 'Response2']):\n",
    "    numeric_features, categorical_features = identify_numeric_categorical(df)\n",
    "    data = drop_duplicates(df)\n",
    "    data = delete_incomplete_data(data, threshold)\n",
    "    data = remove_oversamples(data)\n",
    "    data = fill_missing_with_mean(data, numeric_features)\n",
    "    data = fill_missing_with_mode(data, categorical_features)\n",
    "    data = remove_incomplete_irrelevant_responses(data, relevant_columns)\n",
    "    data = handle_outliers(data, numeric_features)\n",
    "    data = normalize_numeric_features(data, numeric_features)\n",
    "    data = one_hot_encode(data, categorical_features)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd1d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e675e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived    Pclass       Age     SibSp     Parch      Fare  \\\n",
      "0    -1.576817  0.988571 -0.339683 -1.073763  0.743576 -0.596221 -0.146892   \n",
      "1    -1.560947  0.988571 -0.339683  0.512383  0.743576 -0.596221 -0.426478   \n",
      "2    -1.481595  0.988571 -0.339683  0.578472  0.743576  0.213363  2.240579   \n",
      "3    -1.465725  0.988571 -0.339683 -1.139853 -0.986026  1.080775 -0.415818   \n",
      "4    -1.449855 -1.011561 -0.339683  0.115846 -0.986026 -0.596221 -0.833098   \n",
      "\n",
      "   Name_Allison, Mr. Hudson Joshua Creighton  Name_Astor, Col. John Jacob  \\\n",
      "0                                          0                            0   \n",
      "1                                          0                            0   \n",
      "2                                          0                            0   \n",
      "3                                          0                            0   \n",
      "4                                          0                            0   \n",
      "\n",
      "   Name_Beattie, Mr. Thomson  ...  Cabin_E60  Cabin_F  Cabin_F E57  \\\n",
      "0                          0  ...          0        0            0   \n",
      "1                          0  ...          0        0            0   \n",
      "2                          0  ...          0        0            0   \n",
      "3                          0  ...          0        0            0   \n",
      "4                          0  ...          0        0            0   \n",
      "\n",
      "   Cabin_F G63  Cabin_F2  Cabin_F33  Cabin_F4  Cabin_G6  Embarked_Q  \\\n",
      "0            0         0          0         0         0           0   \n",
      "1            0         0          0         0         0           0   \n",
      "2            0         0          0         0         0           0   \n",
      "3            0         0          0         0         0           0   \n",
      "4            0         0          0         0         0           0   \n",
      "\n",
      "   Embarked_S  \n",
      "0           1  \n",
      "1           1  \n",
      "2           0  \n",
      "3           0  \n",
      "4           1  \n",
      "\n",
      "[5 rows x 232 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define your DataFrame\n",
    "data = pd.read_csv('C:\\\\Users\\\\Hp Probook\\\\Desktop\\\\final\\\\tested.csv')\n",
    "\n",
    "# Define your numeric and categorical features\n",
    "numeric_features, categorical_features = identify_numeric_categorical(data)\n",
    "\n",
    "# Specify relevant columns for removing incomplete rows\n",
    "relevant_columns = ['Response1', 'Response2']\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessed_data = preprocess_data(data, numeric_features, categorical_features, relevant_columns=relevant_columns)\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(preprocessed_data.head())\n",
    "\n",
    "# You can continue with further analysis or modeling using the preprocessed_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf2b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
